{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a81a01-b198-45da-ae73-00d5f0356d5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Query process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d49dfd2-9b29-48b4-9913-3d4a06d0d4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Tải dữ liệu cho nltk nếu cần\n",
    "nltk.download('punkt')\n",
    "\n",
    "def count_tokens(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83141c1-768e-4159-8af1-181cf07bea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5329\n"
     ]
    }
   ],
   "source": [
    "path = '../Raw_data/LegalQA_COLING2020/exp1_train_ground_truth.jsonl'\n",
    "train_data = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        train_data.append(json.loads(line))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e15bbe0-f9f2-40a3-9532-9889bd9de09d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593\n"
     ]
    }
   ],
   "source": [
    "path = '../Raw_data/LegalQA_COLING2020/exp1_test_ground_truth.jsonl'\n",
    "test_data = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        test_data.append(json.loads(line))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3214f416-862b-4710-b04e-a3ca062a1669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def find_corpus(json_query_file, json_file_corpus):\n",
    "    query_data = load_json(json_query_file)\n",
    "    corpus_data = load_json(json_file_corpus)\n",
    "    with open(json_file_corpus, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            corpus_data.append(json.loads(line))\n",
    "            \n",
    "    questions = []\n",
    "    relevant_corpus = []            \n",
    "    for index, query in enumerate(query_data):\n",
    "        if index % 100 == 0:\n",
    "            print(\"Processing at index \", index)\n",
    "\n",
    "        if len(query.get(\"documents\")) == 1:\n",
    "\n",
    "            relevant_doc_code = query.get(\"documents\")[0].get(\"code\")\n",
    "            relevant_articles_dieu = query.get(\"documents\")[0].get(\"articles\")[0].get(\"name\")\n",
    "            #relevant_articles_khoan = query.get(\"documents\")[0].get(\"articles\")[0].get(\"clauses\")[0].get(\"name\")\n",
    "            #print(relevant_doc_code)\n",
    "            #print(relevant_articles_dieu)\n",
    "            #print(relevant_articles_khoan)\n",
    "            #print(questions[0])\n",
    "            for corpus in corpus_data:\n",
    "                if corpus.get(\"so_hieu\") == relevant_doc_code:\n",
    "                    for item in corpus.get(\"cac_dieu\"):\n",
    "                        if item.get(\"ten_dieu\") == relevant_articles_dieu and count_tokens(str(item.get(\"noi_dung\"))) < 4000:\n",
    "                            text = corpus.get(\"loai_van_ban\") + \" số \" + corpus.get(\"so_hieu\")+'\\n' + str(item.get(\"ten_dieu\"))+ \": \" + str(item.get(\"tieu_de\"))+ '\\n' + str(item.get(\"noi_dung\"))   \n",
    "                            questions.append(query.get(\"query\"))\n",
    "                            relevant_corpus.append(text)\n",
    "                            \n",
    "            \n",
    "    return questions, relevant_corpus\n",
    "\n",
    "json_train_query_file = '../Raw_data/LegalQA_COLING2020/exp1_train_ground_truth.jsonl'\n",
    "json_test_query_file = '../Raw_data/LegalQA_COLING2020/exp1_test_ground_truth.jsonl'\n",
    "json_file_corpus = '../Raw_data/LegalQA_COLING2020/original_2020_04_09.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ead7646e-26f4-428e-a5e7-56ad0569e22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing at index  0\n",
      "Processing at index  100\n",
      "Processing at index  200\n",
      "Processing at index  300\n",
      "Processing at index  400\n",
      "Processing at index  500\n",
      "Processing at index  600\n",
      "Processing at index  700\n",
      "Processing at index  800\n",
      "Processing at index  900\n",
      "Processing at index  1000\n",
      "Processing at index  1100\n",
      "Processing at index  1200\n",
      "Processing at index  1300\n",
      "Processing at index  1400\n",
      "Processing at index  1500\n",
      "Processing at index  1600\n",
      "Processing at index  1700\n",
      "Processing at index  1800\n",
      "Processing at index  1900\n",
      "Processing at index  2000\n",
      "Processing at index  2100\n",
      "Processing at index  2200\n",
      "Processing at index  2300\n",
      "Processing at index  2400\n",
      "Processing at index  2500\n",
      "Processing at index  2600\n",
      "Processing at index  2700\n",
      "Processing at index  2800\n",
      "Processing at index  2900\n",
      "Processing at index  3000\n",
      "Processing at index  3100\n",
      "Processing at index  3200\n",
      "Processing at index  3300\n",
      "Processing at index  3400\n",
      "Processing at index  3500\n",
      "Processing at index  3600\n",
      "Processing at index  3700\n",
      "Processing at index  3800\n",
      "Processing at index  3900\n",
      "Processing at index  4000\n",
      "Processing at index  4100\n",
      "Processing at index  4200\n",
      "Processing at index  4300\n",
      "Processing at index  4400\n",
      "Processing at index  4500\n",
      "Processing at index  4600\n",
      "Processing at index  4700\n",
      "Processing at index  4800\n",
      "Processing at index  4900\n",
      "Processing at index  5000\n",
      "Processing at index  5100\n",
      "Processing at index  5200\n",
      "Processing at index  5300\n",
      "Size of training dataset:  8380\n"
     ]
    }
   ],
   "source": [
    "train_questions, train_relevant_corpus = find_corpus(json_train_query_file, json_file_corpus)\n",
    "print(\"Size of training dataset: \", len(train_questions))\n",
    "train_df = pd.DataFrame({\"query\": train_questions, 'corpus': train_relevant_corpus})\n",
    "train_df = train_df.drop_duplicates()\n",
    "train_df.to_excel(\"../Raw_data/LegalQA_COLING2020/training_qc_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1c714b7-d29d-48ac-852f-252ec53957fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4172, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f2b4d02-2d72-48d1-944d-1595ecf2b7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing at index  0\n",
      "Processing at index  100\n",
      "Processing at index  200\n",
      "Processing at index  300\n",
      "Processing at index  400\n",
      "Processing at index  500\n",
      "Size of test dataset:  920\n"
     ]
    }
   ],
   "source": [
    "test_questions, test_relevant_corpus = find_corpus(json_test_query_file, json_file_corpus)\n",
    "print(\"Size of test dataset: \", len(test_questions))\n",
    "test_df = pd.DataFrame({\"query\": test_questions, 'corpus': test_relevant_corpus})\n",
    "test_df = test_df.drop_duplicates()\n",
    "test_df.to_excel(\"../Raw_data/LegalQA_COLING2020/testing_qc_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6987469a-587d-4be9-bf88-e171a7f47491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03d8ba-15c8-4702-b810-95751ba2f2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLamaIndex",
   "language": "python",
   "name": "llamaindex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
